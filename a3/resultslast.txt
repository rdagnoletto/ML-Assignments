#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Mar 26 13:04:43 2019

@author: ragnoletto
"""
D = 100, K=5
def gMM():
    X = tf.placeholder(tf.float32,[None, dim], name="X")
    mu = tf.get_variable('mean',dtype = tf.float32,shape = [K,dim], initializer = tf.truncated_normal_initializer(stddev=2))
    
    phi = tf.get_variable('stdDev',dtype = tf.float32,shape = [K,1],initializer = tf.truncated_normal_initializer(mean=4,stddev=0.5))
    #sigma = tf.pow(phi,2)
    sigma = tf.abs(phi)

    
    psi = tf.get_variable('logPiProb',dtype = tf.float32,shape = [K,1], initializer = tf.truncated_normal_initializer(mean=1,stddev=0.25))
    log_pi = hlp.logsoftmax(psi)

    log_PDF = log_GaussPDF(X, mu, sigma)
    log_rnj = log_posterior(log_PDF, log_pi)
    lossfunc = neg_log_likelihood(log_PDF, log_pi)
    belong = tf.arg_max(log_rnj,dimension = 1)
    optimizer = tf.train.AdamOptimizer(learning_rate = 0.05, beta1=0.9, beta2=0.99, epsilon=1e-5)
    train = optimizer.minimize(loss=lossfunc)
    return X,mu,sigma,lossfunc,log_pi,log_PDF,log_rnj,train,belong
 
K=5   
Counter({0: 2215, 3: 1778, 4: 1367, 1: 1307})
Counter({0: 1161, 3: 846, 1: 693, 4: 633})
Final Training Loss:  30155.678
Final Validation Loss:  15119.109

Final sigma:  [[24.648119 ]
 [ 8.03342  ]
 [ 6.0991817]
 [12.8815565]
 [ 9.100573 ]]
Final log pi:  [[-0.6612251]
 [-1.8864878]
 [-7.6394854]
 [-1.7485799]
 [-1.8472118]]
 
 
 
K=10

Counter({1: 2021, 6: 1367, 5: 1322, 8: 1307, 9: 650})
Counter({1: 979, 8: 693, 5: 678, 6: 633, 9: 350})
Final Training Loss:  29394.38
Final Validation Loss:  14726.586

Final sigma:  [[ 6.6478353]
 [22.40433  ]
 [ 5.778818 ]
 [12.90002  ]
 [ 5.66792  ]
 [18.0566   ]
 [ 7.0670586]
 [ 6.037612 ]
 [12.178116 ]
 [ 4.429267 ]]
Final log pi:  [[-7.641652 ]
 [-1.1315677]
 [-7.7463417]
 [-6.220504 ]
 [-9.217827 ]
 [-1.6502082]
 [-1.6255999]
 [-8.085298 ]
 [-1.6588047]
 [-2.353931 ]]
 
 
 K=15
 
 Counter({9: 2021, 7: 1367, 0: 1322, 8: 1307, 2: 650})
Counter({9: 979, 8: 693, 0: 678, 7: 633, 2: 350})
Final Training Loss:  29239.518
Final Validation Loss:  14648.619

Final sigma:  [[23.120388 ]
 [ 8.954913 ]
 [ 6.138508 ]
 [ 5.68269  ]
 [ 8.213345 ]
 [ 9.041283 ]
 [ 5.737563 ]
 [ 9.149303 ]
 [11.76718  ]
 [20.312317 ]
 [ 6.22716  ]
 [ 7.7068715]
 [ 5.5133624]
 [ 8.862666 ]
 [ 6.5244875]]
Final log pi:  [[-1.568387 ]
 [-6.4941792]
 [-2.3657823]
 [-7.581526 ]
 [-8.356365 ]
 [-4.9403906]
 [-9.373861 ]
 [-1.6634154]
 [-1.7037067]
 [-1.1764455]
 [-8.240028 ]
 [-8.180656 ]
 [-9.415679 ]
 [-4.966434 ]
 [-7.1499686]]
 
 K=20
 
Counter({0: 2020, 8: 1367, 14: 1323, 5: 1307, 11: 650})
Counter({0: 978, 5: 693, 14: 679, 8: 633, 11: 350})
Final Training Loss:  29278.252
Final Validation Loss:  14649.309

Final sigma:  [[10.040725 ]
 [ 3.356871 ]
 [12.626341 ]
 [ 5.5524993]
 [ 1.2704089]
 [12.817027 ]
 [ 5.6152296]
 [ 8.032126 ]
 [ 9.033022 ]
 [13.367916 ]
 [ 5.427177 ]
 [ 1.2772119]
 [ 6.678755 ]
 [ 3.4861107]
 [27.274075 ]
 [ 5.7169247]
 [ 5.3119693]
 [ 3.4362798]
 [ 5.6319413]
 [ 6.188081 ]]
Final log pi:  [[-1.5198736]
 [-9.449995 ]
 [-8.339245 ]
 [-7.75984  ]
 [-6.111004 ]
 [-1.7968259]
 [-9.940735 ]
 [-8.631561 ]
 [-1.7689257]
 [-8.611637 ]
 [-9.882305 ]
 [-2.4673033]
 [-7.7179394]
 [-9.723809 ]
 [-1.0339785]
 [-8.860258 ]
 [-8.625879 ]
 [-9.759966 ]
 [-9.250551 ]
 [-9.066065 ]]
 
 K=30
 
Counter({2: 2021, 7: 1367, 26: 1322, 4: 1307, 3: 650})
Counter({2: 979, 4: 693, 26: 678, 7: 633, 3: 350})
Final Training Loss:  28717.031
Final Validation Loss:  14374.426


Final sigma:  [[ 6.1045113]
 [13.29596  ]
 [23.42971  ]
 [ 1.5929362]
 [10.38726  ]
 [ 8.453452 ]
 [ 5.521256 ]
 [ 9.144945 ]
 [ 5.6249676]
 [ 6.9695635]
 [ 7.037581 ]
 [ 8.208211 ]
 [ 8.176843 ]
 [ 5.569924 ]
 [ 7.384004 ]
 [ 7.395604 ]
 [ 6.182825 ]
 [ 5.862272 ]
 [ 6.392672 ]
 [11.87933  ]
 [10.575838 ]
 [ 7.208489 ]
 [ 7.436039 ]
 [10.304189 ]
 [ 6.6217146]
 [ 5.7177844]
 [27.85846  ]
 [12.62668  ]
 [ 5.502292 ]
 [ 5.6618896]]
Final log pi:  [[-10.005434 ]
 [ -6.897786 ]
 [ -1.1882257]
 [ -2.387189 ]
 [ -1.7208242]
 [ -9.669098 ]
 [-11.708347 ]
 [ -1.7061167]
 [ -8.639264 ]
 [-11.276788 ]
 [-10.982132 ]
 [-10.001139 ]
 [ -9.625512 ]
 [ -9.183496 ]
 [ -5.8127427]
 [ -9.189085 ]
 [-11.404862 ]
 [-10.835509 ]
 [-11.653503 ]
 [ -7.5719414]
 [ -9.170695 ]
 [ -9.645347 ]
 [ -8.149894 ]
 [ -9.875679 ]
 [ -9.843362 ]
 [-10.313959 ]
 [ -1.4430718]
 [ -7.065337 ]
 [-11.539928 ]
 [-11.517614 ]]